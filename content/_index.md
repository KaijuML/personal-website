---
Lastmod: 2021-04-08
sitemap:
    Priority: "1"
    ChangeFreq: "monthly"
---


## About Me


I am a third year **PhD** student at **Sorbonne Université**, and a **Research Engineer** at **BNP Paribas**. 

My PhD, _Deep Learning for Data-to-Text Generation_ is done under the supervision of [Patrick Gallinari][1] and [Laure Soulier][2], from the [MLIA][3] team. In the last year, I have focused on working with other PhD students, with notably fruitful collaborations with University of Turin (Italy) and University of Aberdeen (UK). All projects (solos \& duos) are available on [Github][4] and [ArXiv][5].


### Academic Research

I am interested in **Data-to-Text Generation** (DTG), i.e. building systems able to:
 - comprehend complex structured data (e.g. tables, graphs, etc.); 
 - produce a fitting description (from one sentence to several paragraphs). 

These systems are crucial in environments  where raw data is abundant, but hardly usable as is (e.g. health, sports, etc.), because end-users are more effective when provided with textual summaries than structured data<sup>1</sup>.

My PhD work has been focused on a critical aspect of DTG: **ensuring factualness in system outputs**. Neural networks have proven shockingly good at producing fluent texts, but end-users care more about accuracy than about readability<sup>2</sup>. Wrong descriptions that must be revised by human experts are of limited utility. In this direction, I have proposed novel encoding neural modules that are better suited for complex structured data, evaluation protocols that can better discriminate between models by leveraging structured data, and training procedures that ensure models don’t pick up on biased human behaviours (such as mentioning unverifiable facts).

### Work

I am a Research Engineer at BNP Paribas. In practice, I bridge the gap between research/academia and applications/enterprise. I am part of the team which developped the internal company-wide search engine, as well as a number of other tools (translation plateform, document NLP, etc.). I also act in an advisory capacity when I can: I have co-supervised an internship on Gramatical Error Correction, and helped write several of my coworkers' research papers (accepted at international conferences).

### Hobbies

On a personal note, I am a climbing enthusiast and used to run/swim at least once per week before COVID. I greatly enjoy storytelling, both reading and going to the movies (used to go twice a week w/ movie pass). I'm also a fan of cooking: meals, deserts, as well as **cocktails** :tropical_drink: See the Gallery Section for some proof that I go outside!


<sub>1: From data to text in the Neonatal Intensive Care Unit: Using NLG technology for decision support and information management. Gatt et al. 2009</sub>  
<sub>2: An Investigation into the Validity of Some Metrics for Automatically Evaluating Natural Language Generation Systems. Belz and Reiter 2009</sub>

[1]: http://www-connex.lip6.fr/~gallinar/gallinari/pmwiki.php 
[2]: https://mlia.lip6.fr/soulier/
[3]: https://mlia.lip6.fr/
[4]: https://github.com/KaijuML
[5]: https://arxiv.org/search/cs?searchtype=author&query=Rebuffel%2C+C